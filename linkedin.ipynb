{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a27e1e3-87fa-4c19-8c23-7c75f7f596a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Scraping Completed! Check 'linkedin_jobs.csv'\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# ✅ Use Headless Mode (Runs in Background)\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\")  \n",
    "options.add_argument(\"--disable-gpu\")  \n",
    "options.add_argument(\"--window-size=1920,1080\")  \n",
    "options.add_argument(\"--no-sandbox\")\n",
    "options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "# ✅ Open LinkedIn Job Search Page (Without Login)\n",
    "driver = webdriver.Chrome(options=options)\n",
    "driver.get(\"https://www.linkedin.com/jobs/search?keywords=Software%20Engineer\")\n",
    "time.sleep(5)  # Wait for page to load\n",
    "\n",
    "job_data = []\n",
    "\n",
    "# ✅ Scrape Job Listings\n",
    "jobs = driver.find_elements(By.CLASS_NAME, \"base-card\")  # LinkedIn job elements\n",
    "\n",
    "for job in jobs[:5]:  # Get only the first 5 jobs\n",
    "    try:\n",
    "        title = job.find_element(By.CLASS_NAME, \"base-search-card__title\").text\n",
    "        company = job.find_element(By.CLASS_NAME, \"base-search-card__subtitle\").text\n",
    "        location = job.find_element(By.CLASS_NAME, \"job-search-card__location\").text\n",
    "        job_url = job.find_element(By.TAG_NAME, \"a\").get_attribute(\"href\")  # Job link\n",
    "\n",
    "        job_data.append({\n",
    "            \"Title\": title,\n",
    "            \"Company\": company,\n",
    "            \"Location\": location,\n",
    "            \"Job URL\": job_url\n",
    "        })\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "# ✅ Save Jobs to CSV\n",
    "df = pd.DataFrame(job_data)\n",
    "ROOT_DIR = Path.cwd()\n",
    "df.to_csv(ROOT_DIR / \"linkedin_jobs.csv\", index=False)\n",
    "\n",
    "print(\"✅ Scraping Completed! Check 'linkedin_jobs.csv'\")\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7a5062f1-b05e-43b8-b801-9e25a117b66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Scraped: Data Scientist (L6) - Product at Netflix\n",
      "✅ Scraped: Data Scientist - Healthcare & Clinical Data (Remote) at Walgreens\n",
      "✅ Scraped: Data Scientist, Growth at Notion\n",
      "✅ Scraped: Data Scientist, Growth at Notion\n",
      "✅ Scraped:  at \n",
      "✅ Scraping Completed! Check '/home/h2/linkedin_data.csv'\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ✅ Setup Chrome Options (Headless Mode)\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\")  \n",
    "options.add_argument(\"--disable-gpu\")  \n",
    "options.add_argument(\"--window-size=1920,1080\")  \n",
    "options.add_argument(\"--no-sandbox\")\n",
    "options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "# ✅ Start WebDriver\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "# ✅ Open LinkedIn Job Search Page (No Login Required)\n",
    "url = \"https://www.linkedin.com/jobs/search/?currentJobId=4130519571&keywords=Data%20Scientist\"\n",
    "driver.get(url)\n",
    "time.sleep(5)  # Wait for page to load\n",
    "\n",
    "job_data = []\n",
    "\n",
    "# ✅ Get All Job Listings\n",
    "jobs = driver.find_elements(By.CLASS_NAME, \"base-card\")  \n",
    "\n",
    "if not jobs:\n",
    "    print(\"❌ No jobs found! LinkedIn might have blocked the scraper.\")\n",
    "else:\n",
    "    for job in jobs[:5]:  # Limit to 5 jobs\n",
    "        try:\n",
    "            # ✅ Click Job to Open Details\n",
    "            driver.execute_script(\"arguments[0].click();\", job)\n",
    "            time.sleep(3)  # Allow time for job details to load\n",
    "\n",
    "            # ✅ Extract Job Details\n",
    "            title = job.find_element(By.CLASS_NAME, \"base-search-card__title\").text\n",
    "            company = job.find_element(By.CLASS_NAME, \"base-search-card__subtitle\").text\n",
    "            location = job.find_element(By.CLASS_NAME, \"job-search-card__location\").text\n",
    "            job_url = job.find_element(By.TAG_NAME, \"a\").get_attribute(\"href\")\n",
    "\n",
    "            # ✅ Wait for Job Description to Load\n",
    "            try:\n",
    "                description = WebDriverWait(driver, 5).until(\n",
    "                    EC.presence_of_element_located((By.CLASS_NAME, \"jobs-description-content__text\"))\n",
    "                ).text\n",
    "            except:\n",
    "                description = \"Not Available\"\n",
    "\n",
    "            # ✅ Extract Additional Info (If Available)\n",
    "            try:\n",
    "                experience = driver.find_element(By.XPATH, \"//span[contains(text(),'Experience')]//following-sibling::span\").text\n",
    "            except:\n",
    "                experience = \"Not Mentioned\"\n",
    "\n",
    "            try:\n",
    "                job_type = driver.find_element(By.XPATH, \"//span[contains(text(),'Employment type')]//following-sibling::span\").text\n",
    "            except:\n",
    "                job_type = \"Not Mentioned\"\n",
    "\n",
    "            try:\n",
    "                salary = driver.find_element(By.XPATH, \"//span[contains(text(),'Pay')]//following-sibling::span\").text\n",
    "            except:\n",
    "                salary = \"Not Mentioned\"\n",
    "\n",
    "            # ✅ Store Job Data\n",
    "            job_data.append({\n",
    "                \"Title\": title,\n",
    "                \"Company\": company,\n",
    "                \"Location\": location,\n",
    "                \"Experience\": experience,\n",
    "                \"Job Type\": job_type,\n",
    "                \"Salary\": salary,\n",
    "                \"Description\": description,\n",
    "                \"Job URL\": job_url\n",
    "            })\n",
    "\n",
    "            print(f\"✅ Scraped: {title} at {company}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error scraping job: {e}\")\n",
    "\n",
    "# ✅ Save Data to CSV\n",
    "df = pd.DataFrame(job_data)\n",
    "ROOT_DIR = Path.cwd()\n",
    "csv_path = ROOT_DIR / \"linkedin_data.csv\"\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"✅ Scraping Completed! Check '{csv_path}'\")\n",
    "driver.quit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
